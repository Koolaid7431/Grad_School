{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "### CHEM ENG/ SEP 786\n",
    "### Mohammad Kashif Siddiqui - 0755452\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import os \n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import random as rn\n",
    "import sklearn.discriminant_analysis\n",
    "import time\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path:\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python35\\Scripts\\Allwork\\SEP_786\n"
     ]
    }
   ],
   "source": [
    "print('current path:')\n",
    "dir_path = os.getcwd()\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data \n",
    "\n",
    "#### Read data in pandas dataframe and transfer to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time in seconds: 0.1020887\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "data = pd.read_csv('EEG_modified.txt', header = None)\n",
    "data = pd.DataFrame.to_numpy(data)\n",
    "toc = time.clock()\n",
    "print('Elapsed time to load data in seconds:', (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing & Training Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data \n",
    "Input_data=data[:,0:14]\n",
    "\n",
    "# Isolate labels\n",
    "labels = data[:,14]\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "train_data, test_data, train_label, test_label = train_test_split(Input_data, labels, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set data shape: (13482, 14)\n",
      "Testing set data shape: (1498, 14)\n",
      "Training set label shape: (13482,)\n",
      "Testing set label shape: (1498,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set data shape:', train_data.shape)\n",
    "print('Testing set data shape:', test_data.shape) \n",
    "print('Training set label shape:', train_label.shape)\n",
    "print('Testing set label shape:', test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data ex: [4258.97 4033.85 4281.54 4150.77 4381.54 4655.38 4106.67 4656.41 4228.72\n",
      " 4242.56 4193.85 4287.18 4597.95 4321.03]\n",
      "train_label ex: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data ex:\", train_data[0])\n",
    "print(\"train_label ex:\", train_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing PCA Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function that Performs PCA\n",
    "#It will be applied to both the test and train data sets\n",
    "\n",
    "def PCA_func(X, num_feats=14, reduce=1, reduce_by=0):\n",
    "    \n",
    "    print('Shape of the original training data is: ', X.shape)\n",
    "    # Center the Means\n",
    "    mean = np.mean(X)\n",
    "    Xc = X - mean\n",
    "    \n",
    "    # EigenValue, EigenVector\n",
    "    D,E = np.linalg.eig(np.dot(Xc.T,Xc))\n",
    "    \n",
    "    # Sort\n",
    "    sortIndex = np.argsort(D)\n",
    "    newE = np.zeros((num_feats, num_feats))\n",
    "    index = 0\n",
    "    for i in range(0,num_feats):\n",
    "        newE[:,index] = E[:,sortIndex[i]]\n",
    "        index = index + 1\n",
    "    print('Shape of the PCAs new basis (E) is:', newE.shape)\n",
    "    \n",
    "    # Reduce dimensions\n",
    "    if reduce == 1 and reduce_by!= 0:  #if you must reduce, specify how much:\n",
    "        newE_reduced = np.delete(newE, np.s_[0:reduce_by], axis=1)\n",
    "        \n",
    "        ##The function deletes the first column because that's the column with the lowest variance explained\n",
    "        ## argsort sorts the data by lowest to highest, therefore the last column explains the most variance.\n",
    "        \n",
    "        print('A reduction in size was performed!')\n",
    "        print('the new shape of E is: ', newE_reduced.shape)\n",
    "    else:\n",
    "        newE_reduced = newE\n",
    "        print('No size reduction performed!')\n",
    "        \n",
    "    # Reconstructing The data\n",
    "    \n",
    "    # Setting up the reconstruction using the formula below:\n",
    "    # X_reconstructed = X_centered . (Eigenvector . (Eigenvector^T)) + np.mean(X_original)\n",
    "    \n",
    "    newE_reduced_transposed = np.dot(newE_reduced, newE_reduced.T)\n",
    "    ynew = np.dot(Xc,newE_reduced_transposed)+mean\n",
    "    \n",
    "    # Return\n",
    "    print('ynew shape: ', ynew.shape)\n",
    "    return ynew\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Method 1: Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the linear discriminant analysis function\n",
    "def FLD_func(train_inputs, train_labels, test_inputs, test_labels):\n",
    "    \n",
    "    tic = time.clock()\n",
    "    # training set result without feature selection\n",
    "    lda = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "    #training\n",
    "    lda.fit(train_inputs, train_labels)\n",
    "    toc = time.clock()\n",
    "    print('Elapsed training time in seconds:', (toc - tic))\n",
    "    \n",
    "    tic = time.clock()\n",
    "    #testing\n",
    "    prediction = lda.predict(test_inputs)\n",
    "    toc = time.clock()\n",
    "    print('Elapsed testing time in seconds:', (toc - tic))\n",
    "    \n",
    "    error = sum(abs(prediction - test_labels))\n",
    "    print(\"total errors = \", error)\n",
    "    \n",
    "    \n",
    "    Conf_mat = sklearn.metrics.confusion_matrix(test_labels, prediction, labels=None, sample_weight=None, normalize=None)\n",
    "    \n",
    "    return Conf_mat\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing PCA with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA with LDA\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "No size reduction performed!\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 0\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.038066700000001674\n",
      "Elapsed testing time in seconds: 0.0007327000000145745\n",
      "total errors =  549.0\n",
      "[[629 190]\n",
      " [359 320]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 13)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 1\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.03457399999999211\n",
      "Elapsed testing time in seconds: 0.0006075000000009823\n",
      "total errors =  569.0\n",
      "[[614 205]\n",
      " [364 315]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 12)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 2\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.03219510000002401\n",
      "Elapsed testing time in seconds: 0.0005806000000063705\n",
      "total errors =  674.0\n",
      "[[581 238]\n",
      " [436 243]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 11)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 3\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.03262709999998492\n",
      "Elapsed testing time in seconds: 0.00038440000000150576\n",
      "total errors =  670.0\n",
      "[[577 242]\n",
      " [428 251]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 10)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 4\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.03404540000002498\n",
      "Elapsed testing time in seconds: 0.0005199999999945248\n",
      "total errors =  696.0\n",
      "[[554 265]\n",
      " [431 248]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 9)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 5\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.03439050000000066\n",
      "Elapsed testing time in seconds: 0.000861200000002782\n",
      "total errors =  676.0\n",
      "[[597 222]\n",
      " [454 225]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 8)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 6\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.033004099999999426\n",
      "Elapsed testing time in seconds: 0.0006719000000146025\n",
      "total errors =  678.0\n",
      "[[587 232]\n",
      " [446 233]]\n",
      "............................................................\n"
     ]
    }
   ],
   "source": [
    "print('Performing PCA with LDA')\n",
    "for i in range (0,7):\n",
    "    print(\"\\n\")\n",
    "    print('............................................................')\n",
    "    PCA = PCA_func(train_data, num_feats=14, reduce=1, reduce_by=i)\n",
    "    print('............................................................')\n",
    "    #print('PCA features removed:', i)\n",
    "    #print('reconstructed data:')\n",
    "    #print(PCA)\n",
    "    #print('............................................................')\n",
    "    print('Confusion matrix: PCA features removed =',i)\n",
    "    print('Shape of testing data is: ', test_data.shape)\n",
    "    confusion_matrix = FLD_func(PCA, train_label, test_data, test_label)\n",
    "    print(confusion_matrix)\n",
    "    print('............................................................')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Method 2: K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": True
   },
   "outputs": [],
   "source": [
    "#data = numpy.loadtxt(\"Data_for_UCI_named.csv\", delimiter = ',')\n",
    "\n",
    "def KNN_func (train_datas, train_labels, test_datas, test_labels):\n",
    "    Xtrain = train_datas\n",
    "    Xtest = test_datas\n",
    "    Xctrain =train_labels\n",
    "    Xctest = test_labels\n",
    "\n",
    "    length_train = train_data.shape[0]\n",
    "    length_test = test_data.shape[0]\n",
    "\n",
    "    k = 7\n",
    "    print('K value: ', k)\n",
    "    dist = np.zeros(length_train)\n",
    "    errors = np.zeros(length_test)\n",
    "    conf = np.zeros(length_test)\n",
    "    tic = time.clock()\n",
    "    for i in range(length_test):\n",
    "\n",
    "        dist = np.sum((Xtrain - Xtest[i,:])**2,axis = 1)**0.5\n",
    "        sortIndex = np.argsort(dist)\n",
    "        bestLabels = Xctrain[sortIndex[0:k]]\n",
    "\n",
    "        prediction = (sum(bestLabels) > k/2.0)*1.0\n",
    "        conf[i] = prediction\n",
    "        errors[i] = (Xctest[i] != prediction)*1.0\n",
    "\n",
    "    toc = time.clock()\n",
    "    print('Elapsed testing time in seconds:', (toc - tic))\n",
    "\n",
    "    #confusion Matrix\n",
    "    Conf_mat = sklearn.metrics.confusion_matrix(Xctest, conf, labels=None, sample_weight=None, normalize=None)\n",
    "    print(\"total errors = \", np.sum(errors))\n",
    "    \n",
    "    #return\n",
    "    return Conf_mat\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing PCA with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA with KNN\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "No size reduction performed!\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 0\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.844952899999981\n",
      "total errors =  43.0\n",
      "[[800  19]\n",
      " [ 24 655]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 13)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 1\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.8183018999999945\n",
      "total errors =  47.0\n",
      "[[799  20]\n",
      " [ 27 652]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 12)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 2\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.993820999999997\n",
      "total errors =  53.0\n",
      "[[799  20]\n",
      " [ 33 646]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 11)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 3\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.745969699999989\n",
      "total errors =  84.0\n",
      "[[788  31]\n",
      " [ 53 626]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 10)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 4\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.80691139999999\n",
      "total errors =  111.0\n",
      "[[774  45]\n",
      " [ 66 613]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 9)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 5\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.938971500000008\n",
      "total errors =  126.0\n",
      "[[764  55]\n",
      " [ 71 608]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "............................................................\n",
      "Shape of the original training data is:  (13482, 14)\n",
      "Shape of the PCAs new basis (E) is: (14, 14)\n",
      "A reduction in size was performed!\n",
      "the new shape of E is:  (14, 8)\n",
      "ynew shape:  (13482, 14)\n",
      "............................................................\n",
      "Confusion matrix: PCA features removed = 6\n",
      "Shape of testing data is:  (1498, 14)\n",
      "K value:  7\n",
      "Elapsed testing time in seconds: 5.868037500000014\n",
      "total errors =  153.0\n",
      "[[758  61]\n",
      " [ 92 587]]\n",
      "............................................................\n"
     ]
    }
   ],
   "source": [
    "print('Performing PCA with KNN')\n",
    "for i in range (0,7):\n",
    "    print(\"\\n\")\n",
    "    print('............................................................')\n",
    "    PCA = PCA_func(train_data, num_feats=14, reduce=1, reduce_by=i)\n",
    "    print('............................................................')\n",
    "    #print('PCA features removed:', i)\n",
    "    #print('reconstructed data:')\n",
    "    #print(PCA)\n",
    "    #print('............................................................')\n",
    "    print('Confusion matrix: PCA features removed =',i)\n",
    "    print('Shape of testing data is: ', test_data.shape)\n",
    "    confusion_matrix = KNN_func(PCA, train_label, test_data, test_label)\n",
    "    print(confusion_matrix)\n",
    "    print('............................................................')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: Forward Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Forward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "jupyter": {
     "source_hidden": True
    }
   },
   "outputs": [],
   "source": [
    "## this one is kept becasue fwd_func was occasionally giving errors and this helps get around some issues.\n",
    "\n",
    "def fwd_func(train_datas, train_labels, test_datas, num_feat, feats_selected):\n",
    "    #num_feat = total features available\n",
    "    #feats_selected = number of features you want to choose\n",
    "\n",
    "    feat_len = train_datas.shape[0]\n",
    "    test_len = test_datas.shape[0]\n",
    "    feat_sel_range = feats_selected +1\n",
    "    num_feat_range = num_feat +1\n",
    "    bestFeature = 100*np.ones(feat_sel_range)\n",
    "    index_of_errors = np.ones(feat_sel_range)\n",
    "    \n",
    "    \n",
    "    for iteration in range(0,feat_sel_range):\n",
    "        if iteration == 0:\n",
    "            Xselection = np.zeros((feat_len,1))\n",
    "        else:\n",
    "            Xselection = np.concatenate((Xselection, np.zeros((feat_len,1))), axis = 1)\n",
    "\n",
    "        error  = 10000*np.ones(num_feat)\n",
    "        for feature in range(num_feat):\n",
    "\n",
    "            # have not used the feature before\n",
    "            if(not(feature in bestFeature )):\n",
    "\n",
    "                    #add a feature to the existing features\n",
    "                    Xselection[:,iteration] = train_datas[:,feature]\n",
    "\n",
    "                    #classify using Xselection\n",
    "                    lda = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "                    lda.fit(Xselection,train_labels)\n",
    "                    prediction = lda.predict(Xselection)\n",
    "                    error[feature] = sum(abs(prediction - train_labels))\n",
    "\n",
    "        bestFeature[iteration] = np.argmin(error)\n",
    "        temp = np.argmin(error)\n",
    "        index_of_errors[iteration] = temp\n",
    "        print('error:', error)\n",
    "        \n",
    "        Xselection[:, iteration] = train_datas[:,int(bestFeature[iteration])]\n",
    "    \n",
    "    return Xselection, index_of_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the linear discriminant analysis function\n",
    "def FLD_func(train_inputs, train_labels, test_inputs, test_labels):\n",
    "    \n",
    "    tic = time.clock()\n",
    "    # training set result without feature selection\n",
    "    lda = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "    #training\n",
    "    lda.fit(train_inputs, train_labels)\n",
    "    toc = time.clock()\n",
    "    print('Elapsed training time in seconds:', (toc - tic))\n",
    "    \n",
    "    tic = time.clock()\n",
    "    #testing\n",
    "    prediction = lda.predict(test_inputs)\n",
    "    toc = time.clock()\n",
    "    print('Elapsed testing time in seconds:', (toc - tic))\n",
    "    \n",
    "    error = sum(abs(prediction - test_labels))\n",
    "    print(\"total errors = \", error)\n",
    "    \n",
    "    \n",
    "    Conf_mat = sklearn.metrics.confusion_matrix(test_labels, prediction, labels=None, sample_weight=None, normalize=None)\n",
    "    \n",
    "    return Conf_mat\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_func1(train_datas, train_labels, test_datas, num_feat, feats_selected):\n",
    "    #num_feat = total features available\n",
    "    #feats_selected = number of features you want to choose\n",
    "\n",
    "    feat_len = train_datas.shape[0]\n",
    "    test_len = test_datas.shape[0]\n",
    "    feat_sel_range = feats_selected +1\n",
    "    num_feat_range = num_feat +1\n",
    "    bestFeature = 100*np.ones(feat_sel_range)\n",
    "    index_of_errors = np.ones(feat_sel_range)\n",
    "    \n",
    "    \n",
    "    for iteration in range(0,feat_sel_range):\n",
    "        if iteration == 0:\n",
    "            Xselection = np.zeros((feat_len,1))\n",
    "            Tselection = np.zeros((test_len,1))\n",
    "        else:\n",
    "            Xselection = np.concatenate((Xselection, np.zeros((feat_len,1))), axis = 1)\n",
    "            Tselection = np.concatenate((Tselection, np.zeros((test_len,1))), axis = 1)\n",
    "        \n",
    "        error  = 10000*np.ones(num_feat)\n",
    "        for feature in range(num_feat):\n",
    "\n",
    "            # have not used the feature before\n",
    "            if(not(feature in bestFeature )):\n",
    "\n",
    "                    #add a feature to the existing features\n",
    "                    Xselection[:,iteration] = train_datas[:,feature]\n",
    "\n",
    "                    #classify using Xselection\n",
    "                    lda = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "                    lda.fit(Xselection,train_labels)\n",
    "                    prediction = lda.predict(Xselection)\n",
    "                    error[feature] = sum(abs(prediction - train_labels))\n",
    "\n",
    "        bestFeature[iteration] = np.argmin(error)\n",
    "        temp = np.argmin(error)\n",
    "        index_of_errors[iteration] = temp\n",
    "        #print('error:', error)\n",
    "        \n",
    "        Xselection[:, iteration] = train_datas[:,int(bestFeature[iteration])]\n",
    "        Tselection[:, iteration] = test_datas[:,int(bestFeature[iteration])]\n",
    "    \n",
    "    return Xselection, index_of_errors, Tselection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing FWD Search with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Forward Feature Selection with LDA\n",
      "\n",
      "\n",
      "features selected: 1\n",
      "Index position of features selected: \n",
      "[1. 9.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 1\n",
      "Shape of testing data is:  (1498, 2)\n",
      "Elapsed training time in seconds: 0.007377100000041992\n",
      "Elapsed testing time in seconds: 0.00020179999995662\n",
      "total errors =  644.0\n",
      "[[782  37]\n",
      " [607  72]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 2\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 2\n",
      "Shape of testing data is:  (1498, 3)\n",
      "Elapsed training time in seconds: 0.008399600000018381\n",
      "Elapsed testing time in seconds: 0.00016959999999244246\n",
      "total errors =  625.0\n",
      "[[750  69]\n",
      " [556 123]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 3\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 3\n",
      "Shape of testing data is:  (1498, 4)\n",
      "Elapsed training time in seconds: 0.010776899999996203\n",
      "Elapsed testing time in seconds: 0.00021490000000312648\n",
      "total errors =  628.0\n",
      "[[754  65]\n",
      " [563 116]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 4\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 4\n",
      "Shape of testing data is:  (1498, 5)\n",
      "Elapsed training time in seconds: 0.012741399999981695\n",
      "Elapsed testing time in seconds: 0.0002178999999955522\n",
      "total errors =  627.0\n",
      "[[754  65]\n",
      " [562 117]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 5\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 5\n",
      "Shape of testing data is:  (1498, 6)\n",
      "Elapsed training time in seconds: 0.01446099999998296\n",
      "Elapsed testing time in seconds: 0.00022580000000971268\n",
      "total errors =  619.0\n",
      "[[747  72]\n",
      " [547 132]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 6\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 6\n",
      "Shape of testing data is:  (1498, 7)\n",
      "Elapsed training time in seconds: 0.01935689999999113\n",
      "Elapsed testing time in seconds: 0.0004941999999914515\n",
      "total errors =  640.0\n",
      "[[670 149]\n",
      " [491 188]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 7\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 7\n",
      "Shape of testing data is:  (1498, 8)\n",
      "Elapsed training time in seconds: 0.018162899999992987\n",
      "Elapsed testing time in seconds: 0.0008186000000023341\n",
      "total errors =  637.0\n",
      "[[670 149]\n",
      " [488 191]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 8\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 8\n",
      "Shape of testing data is:  (1498, 9)\n",
      "Elapsed training time in seconds: 0.021697599999981776\n",
      "Elapsed testing time in seconds: 0.0009374999999636202\n",
      "total errors =  559.0\n",
      "[[673 146]\n",
      " [413 266]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 9\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 9\n",
      "Shape of testing data is:  (1498, 10)\n",
      "Elapsed training time in seconds: 0.023123599999962607\n",
      "Elapsed testing time in seconds: 0.0003849000000286651\n",
      "total errors =  550.0\n",
      "[[655 164]\n",
      " [386 293]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 10\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 10\n",
      "Shape of testing data is:  (1498, 11)\n",
      "Elapsed training time in seconds: 0.02562569999997777\n",
      "Elapsed testing time in seconds: 0.0005594999999516403\n",
      "total errors =  579.0\n",
      "[[640 179]\n",
      " [400 279]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 11\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 11\n",
      "Shape of testing data is:  (1498, 12)\n",
      "Elapsed training time in seconds: 0.027440899999987778\n",
      "Elapsed testing time in seconds: 0.000624299999969935\n",
      "total errors =  560.0\n",
      "[[624 195]\n",
      " [365 314]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 12\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.  0.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 12\n",
      "Shape of testing data is:  (1498, 13)\n",
      "Elapsed training time in seconds: 0.02972880000004352\n",
      "Elapsed testing time in seconds: 0.0006415999999944688\n",
      "total errors =  556.0\n",
      "[[631 188]\n",
      " [368 311]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 13\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.  0.  2.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 13\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed training time in seconds: 0.03252759999998034\n",
      "Elapsed testing time in seconds: 0.0007817999999701897\n",
      "total errors =  549.0\n",
      "[[629 190]\n",
      " [359 320]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 14\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.  0.  2.  0.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 14\n",
      "Shape of testing data is:  (1498, 15)\n",
      "Elapsed training time in seconds: 0.03303470000003017\n",
      "Elapsed testing time in seconds: 0.0003848000000061802\n",
      "total errors =  549.0\n",
      "[[629 190]\n",
      " [359 320]]\n",
      "............................................................\n"
     ]
    }
   ],
   "source": [
    "length = test_data.shape[0]\n",
    "print('Performing Forward Feature Selection with LDA')\n",
    "for i in range (1,15):\n",
    "    print(\"\\n\")\n",
    "    #print('............................................................')\n",
    "    FWD, ind, testdata= fwd_func1(train_data, train_label, test_data, 14, i)\n",
    "    #print('............................................................')\n",
    "    print('features selected:', i)\n",
    "    #print('new dataset:')\n",
    "    #print('FWD search features selected: ')\n",
    "    #print(FWD)\n",
    "    print('Index position of features selected: ')\n",
    "    print(ind)\n",
    "    #print('FWD search features (for test set) selected: ')\n",
    "    #print(testdata)\n",
    "\n",
    "    print('............................................................')\n",
    "    print('Confusion matrix: features selected =',i)\n",
    "    print('Shape of testing data is: ', testdata.shape)\n",
    "    confusion_matrix = FLD_func(FWD, train_label, testdata, test_label)\n",
    "    print(confusion_matrix)\n",
    "    print('............................................................')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": True
   },
   "outputs": [],
   "source": [
    "def KNN_func (train_datas, train_labels, test_datas, test_labels):\n",
    "    Xtrain = train_datas\n",
    "    Xtest = test_datas\n",
    "    Xctrain =train_labels\n",
    "    Xctest = test_labels\n",
    "\n",
    "    length_train = train_data.shape[0]\n",
    "    length_test = test_data.shape[0]\n",
    "\n",
    "    k = 7\n",
    "    dist = np.zeros(length_train)\n",
    "    errors = np.zeros(length_test)\n",
    "    conf = np.zeros(length_test)\n",
    "    tic = time.clock()\n",
    "    for i in range(length_test):\n",
    "\n",
    "        dist = np.sum((Xtrain - Xtest[i,:])**2,axis = 1)**0.5\n",
    "        sortIndex = np.argsort(dist)\n",
    "        bestLabels = Xctrain[sortIndex[0:k]]\n",
    "\n",
    "        prediction = (sum(bestLabels) > k/2.0)*1.0\n",
    "        conf[i] = prediction\n",
    "        errors[i] = (Xctest[i] != prediction)*1.0\n",
    "\n",
    "    toc = time.clock()\n",
    "    print('Elapsed testing time in seconds:', (toc - tic))\n",
    "\n",
    "    #confusion Matrix\n",
    "    Conf_mat = sklearn.metrics.confusion_matrix(Xctest, conf, labels=[1,0], sample_weight=None, normalize=None)\n",
    "    print(\"total errors = \", np.sum(errors))\n",
    "    \n",
    "    #return\n",
    "    return Conf_mat\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Feature Selection with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Forward Feature Selection with KNN\n",
      "\n",
      "\n",
      "features selected: 1\n",
      "Index position of features selected: \n",
      "[1. 9.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 1\n",
      "Shape of testing data is:  (1498, 2)\n",
      "Elapsed testing time in seconds: 1.896891099999948\n",
      "total errors =  644.0\n",
      "[[307 372]\n",
      " [272 547]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 2\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 2\n",
      "Shape of testing data is:  (1498, 3)\n",
      "Elapsed testing time in seconds: 1.979744299999993\n",
      "total errors =  538.0\n",
      "[[366 313]\n",
      " [225 594]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 3\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 3\n",
      "Shape of testing data is:  (1498, 4)\n",
      "Elapsed testing time in seconds: 1.9769754999999805\n",
      "total errors =  466.0\n",
      "[[422 257]\n",
      " [209 610]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 4\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 4\n",
      "Shape of testing data is:  (1498, 5)\n",
      "Elapsed testing time in seconds: 2.0492210999999543\n",
      "total errors =  394.0\n",
      "[[462 217]\n",
      " [177 642]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 5\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 5\n",
      "Shape of testing data is:  (1498, 6)\n",
      "Elapsed testing time in seconds: 2.1714105999999447\n",
      "total errors =  256.0\n",
      "[[520 159]\n",
      " [ 97 722]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 6\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 6\n",
      "Shape of testing data is:  (1498, 7)\n",
      "Elapsed testing time in seconds: 2.1675723000000744\n",
      "total errors =  209.0\n",
      "[[562 117]\n",
      " [ 92 727]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 7\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 7\n",
      "Shape of testing data is:  (1498, 8)\n",
      "Elapsed testing time in seconds: 2.19617130000006\n",
      "total errors =  150.0\n",
      "[[602  77]\n",
      " [ 73 746]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 8\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 8\n",
      "Shape of testing data is:  (1498, 9)\n",
      "Elapsed testing time in seconds: 2.2724431000000322\n",
      "total errors =  114.0\n",
      "[[617  62]\n",
      " [ 52 767]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 9\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 9\n",
      "Shape of testing data is:  (1498, 10)\n",
      "Elapsed testing time in seconds: 4.680862100000013\n",
      "total errors =  82.0\n",
      "[[630  49]\n",
      " [ 33 786]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 10\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 10\n",
      "Shape of testing data is:  (1498, 11)\n",
      "Elapsed testing time in seconds: 5.065412899999956\n",
      "total errors =  64.0\n",
      "[[644  35]\n",
      " [ 29 790]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 11\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 11\n",
      "Shape of testing data is:  (1498, 12)\n",
      "Elapsed testing time in seconds: 5.368615599999998\n",
      "total errors =  61.0\n",
      "[[643  36]\n",
      " [ 25 794]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 12\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.  0.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 12\n",
      "Shape of testing data is:  (1498, 13)\n",
      "Elapsed testing time in seconds: 5.538240500000029\n",
      "total errors =  51.0\n",
      "[[649  30]\n",
      " [ 21 798]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 13\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.  0.  2.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 13\n",
      "Shape of testing data is:  (1498, 14)\n",
      "Elapsed testing time in seconds: 5.941423200000031\n",
      "total errors =  43.0\n",
      "[[655  24]\n",
      " [ 19 800]]\n",
      "............................................................\n",
      "\n",
      "\n",
      "features selected: 14\n",
      "Index position of features selected: \n",
      "[ 1.  9. 11.  7.  4.  6.  3. 13.  5. 10. 12.  8.  0.  2.  0.]\n",
      "............................................................\n",
      "Confusion matrix: features selected = 14\n",
      "Shape of testing data is:  (1498, 15)\n",
      "Elapsed testing time in seconds: 6.440348699999959\n",
      "total errors =  47.0\n",
      "[[652  27]\n",
      " [ 20 799]]\n",
      "............................................................\n"
     ]
    }
   ],
   "source": [
    "length = test_data.shape[0]\n",
    "print('Performing Forward Feature Selection with KNN')\n",
    "for i in range (1,15):\n",
    "    print(\"\\n\")\n",
    "    #print('............................................................')\n",
    "    FWD, ind, testdata= fwd_func1(train_data, train_label, test_data, 14, i)\n",
    "    #print('............................................................')\n",
    "    print('features selected:', i)\n",
    "    #print('new dataset:')\n",
    "    #print('FWD search features selected: ')\n",
    "    #print(FWD)\n",
    "    print('Index position of features selected: ')\n",
    "    print(ind)\n",
    "    #print('FWD search features (for test set) selected: ')\n",
    "    #print(testdata)\n",
    "\n",
    "    print('............................................................')\n",
    "    print('Confusion matrix: features selected =',i)\n",
    "    print('Shape of testing data is: ', testdata.shape)\n",
    "    confusion_matrix = KNN_func(FWD, train_label, testdata, test_label)\n",
    "    print(confusion_matrix)\n",
    "    print('............................................................')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt # 2\n",
    "- Reduced the dataset to match classes 0 & 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "preg = pd.read_csv('lab_results2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeF</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>0.461997</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0            6  0.743719       0.590164       0.353535  0.000000  0.500745   \n",
       "1            8  0.919598       0.524590       0.000000  0.000000  0.347243   \n",
       "2            0  0.688442       0.327869       0.353535  0.198582  0.642325   \n",
       "3            3  0.391960       0.409836       0.323232  0.104019  0.461997   \n",
       "4            2  0.989950       0.573770       0.454545  0.641844  0.454545   \n",
       "\n",
       "   DiabetesPedigreeF  Age  Outcome  \n",
       "0           0.234415   50        1  \n",
       "1           0.253629   32        1  \n",
       "2           0.943638   33        1  \n",
       "3           0.072588   26        1  \n",
       "4           0.034159   53        1  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preg.head()\n",
    "#preg.describe()\n",
    "#preg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeF</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>0.461997</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0            6  0.743719       0.590164       0.353535  0.000000  0.500745   \n",
       "1            8  0.919598       0.524590       0.000000  0.000000  0.347243   \n",
       "2            0  0.688442       0.327869       0.353535  0.198582  0.642325   \n",
       "3            3  0.391960       0.409836       0.323232  0.104019  0.461997   \n",
       "4            2  0.989950       0.573770       0.454545  0.641844  0.454545   \n",
       "\n",
       "   DiabetesPedigreeF  Age  \n",
       "0           0.234415   50  \n",
       "1           0.253629   32  \n",
       "2           0.943638   33  \n",
       "3           0.072588   26  \n",
       "4           0.034159   53  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preg.drop('Outcome',axis=1) #axis is referring to row vs. column\n",
    "y = preg['Outcome']\n",
    "type(X)\n",
    "X.shape\n",
    "X.describe()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "As Fundamental step you need to split data to train and test; to do so, you can levelrage SciKit Learn's train_test_split function from model_selection. Feel free to check it out here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Standardize features by removing the mean and scaling to unit variance\n",
    "\n",
    "The standard score of a sample x is calculated as z = (x - u) / s\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#help(StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #normalizing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pregnancies           4.022822\n",
      "Glucose               0.630455\n",
      "BloodPressure         0.565166\n",
      "SkinThickness         0.214112\n",
      "Insulin               0.101510\n",
      "BMI                   0.485629\n",
      "DiabetesPedigreeF     0.179385\n",
      "Age                  33.641079\n",
      "dtype: float64\n",
      "Help on method fit in module sklearn.preprocessing._data:\n",
      "\n",
      "fit(X, y=None) method of sklearn.preprocessing._data.StandardScaler instance\n",
      "    Compute the mean and std to be used for later scaling.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      "        The data used to compute the mean and standard deviation\n",
      "        used for later scaling along the features axis.\n",
      "    \n",
      "    y\n",
      "        Ignored\n",
      "\n",
      "[ 4.02282158  0.63045518  0.56516563  0.21411208  0.10151016  0.48562868\n",
      "  0.17938528 33.64107884]\n"
     ]
    }
   ],
   "source": [
    "# Fit only to the training data\n",
    "print(np.mean(X_train, axis=0))\n",
    "scaler.fit(X_train)\n",
    "help(scaler.fit)\n",
    "print(scaler.mean_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain:      pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "456            2  0.603015       0.622951       0.373737  0.124113  0.591654   \n",
      "129            1  0.904523       0.000000       0.000000  0.000000  0.645306   \n",
      "221            0  0.899497       0.409836       0.363636  0.187943  0.563338   \n",
      "162            8  0.758794       0.639344       0.323232  0.248227  0.639344   \n",
      "133            5  0.000000       0.655738       0.323232  0.000000  0.611028   \n",
      "..           ...       ...            ...            ...       ...       ...   \n",
      "424            2  0.452261       0.655738       0.141414  0.065012  0.363636   \n",
      "449            0  0.391960       0.721311       0.292929  0.047281  0.549925   \n",
      "479            8  0.477387       0.590164       0.000000  0.000000  0.548435   \n",
      "377            4  0.552764       0.540984       0.000000  0.000000  0.475410   \n",
      "489           12  0.442211       0.606557       0.404040  0.063830  0.526080   \n",
      "\n",
      "     DiabetesPedigreeF  Age  \n",
      "456           0.058497   29  \n",
      "129           0.087105   41  \n",
      "221           0.160974   22  \n",
      "162           0.187020   36  \n",
      "133           0.114432   37  \n",
      "..                 ...  ...  \n",
      "424           0.073015   24  \n",
      "449           0.152007   21  \n",
      "479           0.173783   57  \n",
      "377           0.167805   29  \n",
      "489           0.128096   48  \n",
      "\n",
      "[482 rows x 8 columns]\n",
      "Xtrain shape: (482, 8)\n",
      "Xtrain1: [[-0.59383861 -0.16032735  0.35069815 ...  0.88152551 -0.809546\n",
      "  -0.41588139]\n",
      " [-0.88740806  1.60132425 -3.42998884 ...  1.32759681 -0.61796816\n",
      "   0.65942391]\n",
      " [-1.18097751  1.57196338 -0.94269477 ...  0.646099   -0.12329702\n",
      "  -1.04314281]\n",
      " ...\n",
      " [ 1.16757807 -0.89434885  0.15171461 ...  0.5221903  -0.0375159\n",
      "   2.0931643 ]\n",
      " [-0.00669972 -0.45393595 -0.14676067 ... -0.08496229 -0.07754708\n",
      "  -0.41588139]\n",
      " [ 2.34185587 -1.09987487  0.25120638 ...  0.33632727 -0.34346856\n",
      "   1.28668533]]\n",
      "Xtrain1 shape: (482, 8)\n",
      "Xtest:      pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "208            7  0.753769       0.639344       0.292929  0.148936  0.524590   \n",
      "124            3  0.562814       0.606557       0.303030  0.000000  0.470939   \n",
      "39             3  0.859296       0.590164       0.333333  0.159574  0.496274   \n",
      "91             0  0.899497       0.737705       0.272727  0.000000  0.657228   \n",
      "143           12  0.703518       0.672131       0.434343  0.384161  0.584203   \n",
      "166            0  0.708543       0.000000       0.000000  0.000000  0.631893   \n",
      "425            0  0.432161       0.557377       0.323232  0.000000  0.533532   \n",
      "80            12  0.758794       0.573770       0.404040  0.320331  0.622951   \n",
      "359            4  0.773869       0.508197       0.313131  0.335697  0.488823   \n",
      "438           13  0.532663       0.573770       0.000000  0.000000  0.509687   \n",
      "306            1  0.477387       0.540984       0.131313  0.044917  0.292101   \n",
      "518            2  0.618090       0.393443       0.323232  0.195035  0.627422   \n",
      "486            3  0.306533       0.672131       0.282828  0.000000  0.512668   \n",
      "37             1  0.819095       0.590164       0.000000  0.000000  0.581222   \n",
      "392            1  0.527638       0.475410       0.000000  0.000000  0.362146   \n",
      "75             8  0.984925       0.622951       0.292929  0.330969  0.558867   \n",
      "434            0  0.512563       0.426230       0.000000  0.000000  0.374069   \n",
      "186            9  0.728643       0.721311       0.343434  0.195035  0.451565   \n",
      "63             5  0.653266       0.672131       0.000000  0.000000  0.582712   \n",
      "522            1  0.718593       0.688525       0.232323  0.366430  0.631893   \n",
      "368            2  0.497487       0.426230       0.151515  0.111111  0.366617   \n",
      "476            1  0.477387       0.606557       0.212121  0.086288  0.385991   \n",
      "244            9  0.824121       0.639344       0.000000  0.000000  0.488823   \n",
      "291            2  0.356784       0.573770       0.272727  0.000000  0.417288   \n",
      "338            3  0.417085       0.475410       0.313131  0.021277  0.511177   \n",
      "240            3  0.849246       0.606557       0.191919  0.147754  0.445604   \n",
      "367            1  0.768844       0.672131       0.424242  0.573286  0.605067   \n",
      "242            1  0.844221       0.721311       0.292929  0.000000  0.521610   \n",
      "130            5  0.577889       0.622951       0.000000  0.000000  0.464978   \n",
      "17             7  0.738693       0.622951       0.000000  0.000000  0.587183   \n",
      "423            2  0.648241       0.688525       0.000000  0.000000  0.417288   \n",
      "31            13  0.633166       0.737705       0.000000  0.000000  0.646796   \n",
      "237           13  0.793970       0.934426       0.000000  0.000000  0.630402   \n",
      "239            7  0.713568       0.737705       0.242424  0.567376  0.453055   \n",
      "462            3  0.497487       0.655738       0.111111  0.075650  0.287630   \n",
      "280            5  0.547739       0.614754       0.262626  0.000000  0.536513   \n",
      "484            4  0.462312       0.655738       0.000000  0.000000  0.628912   \n",
      "241            6  0.628141       0.639344       0.313131  0.000000  0.411326   \n",
      "348            1  0.592965       0.475410       0.363636  0.111111  0.496274   \n",
      "427            2  0.572864       0.557377       0.222222  0.000000  0.427720   \n",
      "295            5  0.442211       0.540984       0.212121  0.027187  0.363636   \n",
      "498            2  0.527638       0.475410       0.404040  0.111111  0.520119   \n",
      "356            3  0.643216       0.639344       0.000000  0.000000  0.314456   \n",
      "251            3  0.653266       0.639344       0.232323  0.093381  0.423249   \n",
      "430            4  0.477387       0.573770       0.323232  0.000000  0.478390   \n",
      "98            11  0.778894       0.622951       0.282828  0.177305  0.496274   \n",
      "13             7  0.984925       0.737705       0.000000  0.000000  0.593145   \n",
      "346            5  0.663317       0.655738       0.000000  0.000000  0.399404   \n",
      "327            6  0.723618       0.590164       0.272727  0.269504  0.505216   \n",
      "408            0  0.507538       0.622951       0.000000  0.000000  0.532042   \n",
      "407            1  0.437186       0.639344       0.272727  0.037825  0.515648   \n",
      "205            3  0.663317       0.655738       0.000000  0.000000  0.512668   \n",
      "496            0  0.592965       0.524590       0.232323  0.105201  0.000000   \n",
      "448            5  0.542714       0.590164       0.434343  0.088652  0.538003   \n",
      "\n",
      "     DiabetesPedigreeF  Age  \n",
      "208           0.262169   54  \n",
      "124           0.050811   25  \n",
      "39            0.051665   24  \n",
      "91            0.259607   23  \n",
      "143           0.192143   58  \n",
      "166           0.054227   29  \n",
      "425           0.068318   25  \n",
      "80            0.283518   38  \n",
      "359           0.067891   23  \n",
      "438           0.073868   52  \n",
      "306           0.109308   25  \n",
      "518           0.188728   26  \n",
      "486           0.070453   46  \n",
      "37            0.488471   33  \n",
      "392           0.046541   21  \n",
      "75            0.225021   57  \n",
      "434           0.000000   21  \n",
      "186           0.295901   53  \n",
      "63            0.374893   37  \n",
      "522           0.426132   22  \n",
      "368           0.238685   21  \n",
      "476           0.254056   36  \n",
      "244           0.029889   45  \n",
      "291           0.216909   22  \n",
      "338           0.110162   25  \n",
      "240           0.081127   31  \n",
      "367           0.260034   23  \n",
      "242           0.353117   52  \n",
      "130           0.113151   44  \n",
      "17            0.076430   43  \n",
      "423           0.087959   27  \n",
      "31            0.215628   42  \n",
      "237           0.076430   44  \n",
      "239           0.021349   43  \n",
      "462           0.087959   30  \n",
      "280           0.199829   60  \n",
      "484           0.067891   29  \n",
      "241           0.207942   49  \n",
      "348           0.078138   23  \n",
      "427           0.005978   25  \n",
      "295           0.112724   30  \n",
      "498           0.062767   25  \n",
      "356           0.081127   55  \n",
      "251           0.104611   34  \n",
      "430           0.228010   24  \n",
      "98            0.544406   51  \n",
      "13            0.159266   41  \n",
      "346           0.046114   69  \n",
      "327           0.075576   40  \n",
      "408           0.051238   26  \n",
      "407           0.009821   22  \n",
      "205           0.138343   44  \n",
      "496           0.705807   21  \n",
      "448           0.078992   33  \n",
      "Xtest1: [[ 0.87400863  0.72049845  0.4501899   0.47406116  0.32115457  0.3239364\n",
      "   0.55437385  1.82433797]\n",
      " [-0.30026917 -0.39521423  0.25120638  0.5348156  -0.68739599 -0.1221349\n",
      "  -0.86101468 -0.77431648]\n",
      " [-0.30026917  1.3370765   0.15171461  0.71707894  0.39319389  0.08850989\n",
      "  -0.85529593 -0.86392526]\n",
      " [-1.18097751  1.57196338  1.04714048  0.35255226 -0.68739599  1.42672376\n",
      "   0.53721763 -0.95353403]\n",
      " [ 2.34185587  0.42688985  0.64917343  1.32462342  1.9140241   0.81957117\n",
      "   0.08543705  2.18277307]\n",
      " [-1.18097751  0.45625071 -3.42998884 -1.28781782 -0.68739599  1.21607898\n",
      "  -0.83813971 -0.41588139]\n",
      " [-1.18097751 -1.15859659 -0.04726891  0.6563245  -0.68739599  0.39828162\n",
      "  -0.74378047 -0.77431648]\n",
      " [ 2.34185587  0.74985931  0.05222286  1.14236008  1.48178814  1.14173377\n",
      "   0.69734239  0.39059758]\n",
      " [-0.00669972  0.83794189 -0.3457442   0.59557005  1.58584495  0.02655554\n",
      "  -0.74663984 -0.95353403]\n",
      " [ 2.63542531 -0.57137939  0.05222286 -1.28781782 -0.68739599  0.2000277\n",
      "  -0.70660865  1.64512042]\n",
      " [-0.88740806 -0.89434885 -0.14676067 -0.49801001 -0.38322995 -1.60903921\n",
      "  -0.46928088 -0.77431648]\n",
      " [-0.59383861 -0.07224477 -1.04218654  0.6563245   0.63332498  1.17890638\n",
      "   0.06256208 -0.68470771]\n",
      " [-0.30026917 -1.89261809  0.64917343  0.41330671 -0.68739599  0.22480944\n",
      "  -0.72948361  1.10746778]\n",
      " [-0.88740806  1.10218963  0.15171461 -1.28781782 -0.68739599  0.79478943\n",
      "   2.06984036 -0.05744629]\n",
      " [-0.88740806 -0.60074025 -0.54472772 -1.28781782 -0.68739599 -1.02666835\n",
      "  -0.88960838 -1.13275158]\n",
      " [ 1.16757807  2.07109801  0.35069815  0.47406116  1.55382747  0.60892639\n",
      "   0.3056086   2.0931643 ]\n",
      " [-1.18097751 -0.68882283 -0.84320301 -1.28781782 -0.68739599 -0.9275414\n",
      "  -1.20127979 -1.13275158]\n",
      " [ 1.46114752  0.57369415  0.94764872  0.77783339  0.63332498 -0.28321619\n",
      "   0.78026414  1.7347292 ]\n",
      " [ 0.28686973  0.13328125  0.64917343 -1.28781782 -0.68739599  0.8071803\n",
      "   1.30924774  0.30098881]\n",
      " [-0.88740806  0.51497243  0.74866519  0.10953447  1.79395856  1.21607898\n",
      "   1.65237223 -1.04314281]\n",
      " [-0.59383861 -0.77690541 -0.84320301 -0.37650111  0.06501474 -0.98949574\n",
      "   0.39710846 -1.13275158]\n",
      " [-0.88740806 -0.89434885  0.25120638 -0.01197443 -0.10307702 -0.82841444\n",
      "   0.50004581  0.21138003]\n",
      " [ 1.46114752  1.13155049  0.4501899  -1.28781782 -0.68739599  0.02655554\n",
      "  -1.00112384  1.017859  ]\n",
      " [-0.59383861 -1.59900949  0.05222286  0.35255226 -0.68739599 -0.56820619\n",
      "   0.25128055 -1.04314281]\n",
      " [-0.30026917 -1.24667917 -0.54472772  0.59557005 -0.54331734  0.21241857\n",
      "  -0.46356214 -0.77431648]\n",
      " [-0.30026917  1.27835479  0.25120638 -0.13348332  0.3131502  -0.33277967\n",
      "  -0.65799935 -0.23666384]\n",
      " [-0.88740806  0.80858103  0.64917343  1.26386897  3.19472322  0.99304334\n",
      "   0.540077   -0.95353403]\n",
      " [-0.88740806  1.24899393  0.94764872  0.47406116 -0.68739599  0.29915466\n",
      "   1.16341983  1.64512042]\n",
      " [ 0.28686973 -0.30713165  0.35069815 -1.28781782 -0.68739599 -0.17169838\n",
      "  -0.44354654  0.92825023]\n",
      " [ 0.87400863  0.63241587  0.35069815 -1.28781782 -0.68739599  0.8443529\n",
      "  -0.68945243  0.83864145]\n",
      " [-0.59383861  0.10392039  0.74866519 -1.28781782 -0.68739599 -0.56820619\n",
      "  -0.61224942 -0.59509894]\n",
      " [ 2.63542531  0.01583781  1.04714048 -1.28781782 -0.68739599  1.33998768\n",
      "   0.24270244  0.74903268]\n",
      " [ 2.63542531  0.95538533  2.24104164 -1.28781782 -0.68739599  1.20368812\n",
      "  -0.68945243  0.92825023]\n",
      " [ 0.87400863  0.48561157  1.04714048  0.17028892  3.15470138 -0.27082532\n",
      "  -1.05831126  0.83864145]\n",
      " [-0.30026917 -0.77690541  0.54968167 -0.6195189  -0.17511634 -1.64621182\n",
      "  -0.61224942 -0.32627261]\n",
      " [ 0.28686973 -0.48329681  0.30095226  0.29179782 -0.68739599  0.42306335\n",
      "   0.13690572  2.36199062]\n",
      " [-0.00669972 -0.98243143  0.54968167 -1.28781782 -0.68739599  1.19129725\n",
      "  -0.74663984 -0.41588139]\n",
      " [ 0.58043918 -0.01352305  0.4501899   0.59557005 -0.68739599 -0.61776966\n",
      "   0.19123377  1.3762941 ]\n",
      " [-0.88740806 -0.21904907 -0.54472772  0.89934229  0.06501474  0.08850989\n",
      "  -0.67801495 -0.95353403]\n",
      " [-0.59383861 -0.33649251 -0.04726891  0.04878002 -0.68739599 -0.48147011\n",
      "  -1.1612486  -0.77431648]\n",
      " [ 0.28686973 -1.09987487 -0.14676067 -0.01197443 -0.50329549 -1.01427748\n",
      "  -0.44640591 -0.32627261]\n",
      " [-0.59383861 -0.60074025 -0.54472772  1.14236008  0.06501474  0.28676379\n",
      "  -0.78095229 -0.77431648]\n",
      " [-0.30026917  0.07455953  0.4501899  -1.28781782 -0.68739599 -1.42317617\n",
      "  -0.65799935  1.91394675]\n",
      " [-0.30026917  0.13328125  0.4501899   0.10953447 -0.0550508  -0.51864271\n",
      "  -0.50073396  0.03216249]\n",
      " [-0.00669972 -0.89434885  0.05222286  0.6563245  -0.68739599 -0.06018055\n",
      "   0.3256242  -0.86392526]\n",
      " [ 2.04828642  0.86730275  0.35069815  0.41330671  0.51325944  0.08850989\n",
      "   2.44441793  1.55551165]\n",
      " [ 0.87400863  2.07109801  1.04714048 -1.28781782 -0.68739599  0.89391638\n",
      "  -0.1347345   0.65942391]\n",
      " [ 0.28686973  0.19200297  0.54968167 -1.28781782 -0.68739599 -0.71689662\n",
      "  -0.89246775  3.16846959]\n",
      " [ 0.58043918  0.54433329  0.15171461  0.35255226  1.13760026  0.16285509\n",
      "  -0.69517117  0.56981513]\n",
      " [-1.18097751 -0.71818369  0.35069815 -1.28781782 -0.68739599  0.38589075\n",
      "  -0.8581553  -0.68470771]\n",
      " [-0.88740806 -1.12923573  0.4501899   0.35255226 -0.43125617  0.24959118\n",
      "  -1.13551427 -1.04314281]\n",
      " [-0.30026917  0.19200297  0.54968167 -1.28781782 -0.68739599  0.22480944\n",
      "  -0.27484367  0.92825023]\n",
      " [-1.18097751 -0.21904907 -0.24625243  0.10953447  0.0249929  -4.03764958\n",
      "   3.52526008 -1.13275158]\n",
      " [ 0.28686973 -0.51265767  0.15171461  1.32462342 -0.08706828  0.43545422\n",
      "  -0.6722962  -0.05744629]]\n",
      "Xtrain mean\n",
      "pregnancies           4.022822\n",
      "Glucose               0.630455\n",
      "BloodPressure         0.565166\n",
      "SkinThickness         0.214112\n",
      "Insulin               0.101510\n",
      "BMI                   0.485629\n",
      "DiabetesPedigreeF     0.179385\n",
      "Age                  33.641079\n",
      "dtype: float64\n",
      "Xtrain1 mean\n",
      "[-7.37077527e-18  3.68538763e-16  1.10561629e-16 -5.52808145e-18\n",
      " -1.43730118e-16 -4.31190353e-16  7.18650589e-17  4.05392640e-17]\n",
      "Xtest mean\n",
      "pregnancies           4.259259\n",
      "Glucose               0.637260\n",
      "BloodPressure         0.600638\n",
      "SkinThickness         0.191171\n",
      "Insulin               0.094169\n",
      "BMI                   0.489209\n",
      "DiabetesPedigreeF     0.162428\n",
      "Age                  35.574074\n",
      "dtype: float64\n",
      "Xtest1 mean\n",
      "[ 0.06941088  0.03976147  0.2152788  -0.13798365 -0.04971455  0.02976798\n",
      " -0.11355398  0.17321333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'\\n    [-1.59936017e+00 -2.82274816e+13 -2.51272754e+13 -6.24895858e+12\\n     -1.40060281e+14 -4.44668650e+15 -5.44836963e+13 -3.08555095e+00]\\n    [-1.59936017e+00 -2.94436316e+13 -2.50638734e+13 -4.13697394e+12\\n     -7.40447989e+13 -4.80290837e+15 -8.48380856e+13 -3.08555095e+00]\\n\\n    # the above block of print out is after 4 reattempts\\n\""
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train \n",
    "X_train1= scaler.transform(X_train)\n",
    "X_test \n",
    "X_test1= scaler.transform(X_test)\n",
    "\n",
    "print('Xtrain:', X_train)\n",
    "print('Xtrain shape:', X_train.shape)\n",
    "print('Xtrain1:', X_train1)\n",
    "print('Xtrain1 shape:', X_train1.shape)\n",
    "\n",
    "print('Xtest:', X_test)\n",
    "print('Xtest1:', X_test1)\n",
    "\n",
    "print('Xtrain mean')\n",
    "print(np.mean(X_train, axis = 0))\n",
    "print('Xtrain1 mean')\n",
    "print(np.mean(X_train1, axis = 0))\n",
    "print('Xtest mean')\n",
    "print(np.mean(X_test, axis = 0))\n",
    "print('Xtest1 mean')\n",
    "print(np.mean(X_test1, axis = 0))\n",
    "\n",
    "#running this block again even after resetting the kernel seems to be reapplying the transform.\n",
    "''''\n",
    "    [-1.59936017e+00 -2.82274816e+13 -2.51272754e+13 -6.24895858e+12\n",
    "     -1.40060281e+14 -4.44668650e+15 -5.44836963e+13 -3.08555095e+00]\n",
    "    [-1.59936017e+00 -2.94436316e+13 -2.50638734e+13 -4.13697394e+12\n",
    "     -7.40447989e+13 -4.80290837e+15 -8.48380856e+13 -3.08555095e+00]\n",
    "\n",
    "    # the above block of print out is after 4 reattempts\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Now it is time to train our model. Import  estimator (the Multi-Layer Perceptron Classifier model) from the neural_network library of SciKit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the model,we will only define the hidden_layer_sizes. \n",
    "For that we pass in a tuple consisting of the number of neurons you want at each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current highest\n",
    "#mlp = MLPClassifier(activation='tanh', batch_size= 20, hidden_layer_sizes=(20,10,1),max_iter=2500, learning_rate='constant',solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLPClassifier(activation='tanh', batch_size= 20, hidden_layer_sizes=(20,10,1),max_iter=2500, learning_rate='adaptive',solver='adam')\n",
    "#max_iter=500\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', batch_size= 100, hidden_layer_sizes=(20,10,1),max_iter=3000, learning_rate='constant', learning_rate_init=0.0005,solver='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been made we can fit the training data to our model, remember that this data has already been processed and scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 10, 1), learning_rate='constant',\n",
       "              learning_rate_init=0.0005, max_fun=15000, max_iter=3000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with parameters and discover what effects they have on your model!\n",
    "\n",
    "## Predictions and Evaluation\n",
    "\n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  7]\n",
      " [ 4 20]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "#help(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81        30\n",
      "           1       0.74      0.83      0.78        24\n",
      "\n",
      "    accuracy                           0.80        54\n",
      "   macro avg       0.80      0.80      0.80        54\n",
      "weighted avg       0.80      0.80      0.80        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.coefs_[0])\n",
    "#mlp.coefs_\n",
    "#mlp.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.intercepts_[0])\n",
    "#mlp.intercepts_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To extract the MLP weights and biases after training your model, you use its public attributes **coefs_** and **intercepts_**. \n",
    "\n",
    "**coefs_** is a list of weight matrices, where weight matrix at index i represents the weights between layer i and layer i+1. \n",
    "\n",
    "**intercepts_** is a list of bias vectors, where the vector at index i represents the bias values added to layer i+1."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

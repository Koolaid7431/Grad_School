{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takes images from Generating_images.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "#import warnings\n",
    "#import csv\n",
    "import gc\n",
    "from time import time\n",
    "import logging\n",
    "#from scipy.io import loadmat\n",
    "#from select_win import select_win,select_windows\n",
    "import load_data as ldfile\n",
    "#import create_model as cmodel\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.device('/device:GPU:0')\n",
    "\n",
    "#from scipy.signal import butter, sosfilt, sosfilt_zi, sosfiltfilt, lfilter, lfilter_zi, filtfilt, sosfreqz, resample\n",
    "#from utils import hamilton_detector, christov_detector, findpeaks, engzee_detector\n",
    "from ecg_detectors.ecgdetectors import Detectors, MWA, panPeakDetect, searchBack\n",
    "\n",
    "np.random.seed(354)\n",
    "#sns.set()\n",
    "#warnings.filterwarnings('ignore')\n",
    "#logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.random.set_seed(1342) # Set seed for reproducibility\n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10898739640230800900\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12671107054397672548\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12663305944450672164\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10561793600\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10773054088001040570\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_dataset type:  <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "val_dataset type:  <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "train_im, train_lab types:  <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "shape of images and labels array:  (26828, 400, 200, 3) (26828, 9)\n",
      "shape of images and labels array ; test:  (3532, 400, 200, 3) (3532, 9)\n"
     ]
    }
   ],
   "source": [
    "# generate the datasets for step 8:\n",
    "train_d = np.load('train_v1.npy')\n",
    "val_d = np.load('val_v1.npy')\n",
    "train_lab = np.load('train_lab_v1.npy')\n",
    "val_lab = np.load('val_lab_v1.npy')\n",
    "\n",
    "train_set_conv,valid_set_conv = ldfile.load_tf(train_d,train_lab,val_d,val_lab)\n",
    "\n",
    "\n",
    "print (\"train_im, train_lab types: \", type(train_d), type(train_lab))\n",
    "#### check the shape of the data\n",
    "print (\"shape of images and labels array: \", train_d.shape, train_lab.shape) \n",
    "print (\"shape of images and labels array ; test: \", val_d.shape, val_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_d, val_d, train_lab, val_lab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = [26828, 12, 2500, 1]\n",
    "val_d = [3532, 12, 2500, 1]\n",
    "train_lab = [26828, 9]\n",
    "val_lab = [3532, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of files:  6877\n",
      "Number of files for trainig:  5501\n",
      "Number of files for validation:  687\n",
      "Number of files for testing:  687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddiqmk/.local/lib/python3.8/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 files were loaded for training!\n",
      "1000 files were loaded for training!\n",
      "1500 files were loaded for training!\n",
      "2000 files were loaded for training!\n",
      "2500 files were loaded for training!\n",
      "3000 files were loaded for training!\n",
      "3500 files were loaded for training!\n",
      "4000 files were loaded for training!\n",
      "4500 files were loaded for training!\n",
      "5000 files were loaded for training!\n",
      "5500 files were loaded for training!\n",
      "499 files were loaded for validation!\n",
      "Labels:\n",
      "0. 164884008\n",
      "1. 164889003\n",
      "2. 164909002\n",
      "3. 164931005\n",
      "4. 270492004\n",
      "5. 284470004\n",
      "6. 426783006\n",
      "7. 429622005\n",
      "8. 59118001\n",
      "\n",
      "number of test signals =  689\n",
      "\n",
      "train_data type: <class 'list'>\n",
      "train_labels  type: <class 'list'>\n",
      "val_data  type: <class 'list'>\n",
      "val_labels  type: <class 'list'>\n",
      "\n",
      "train_data length 26828\n",
      "train_labels length 26828\n",
      "val_data length: 3532\n",
      "val_labels length: 3532\n",
      "\n",
      "train_data type: <class 'numpy.ndarray'>\n",
      "train_labels_bin  type: <class 'numpy.ndarray'>\n",
      "val_data  type: <class 'numpy.ndarray'>\n",
      "val_labels_bin  type: <class 'numpy.ndarray'>\n",
      "\n",
      "train_data.shape: (26828, 12, 2500)\n",
      "train_labels.shape: (26828, 9)\n",
      "val_data.shape: (3532, 12, 2500)\n",
      "val_labels.shape: (3532, 9)\n",
      "\n",
      "train_data.shape: (26828, 12, 2500, 1)\n",
      "val_data.shape: (3532, 12, 2500, 1)\n",
      "\n",
      "train_dataset type:  <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "val_dataset type:  <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Loading data in 106 seconds.\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    t1 = time()\n",
    "    input_directory = '/dataset/PhysioNet2020/Training_WFDB' # Dataset on beastie \n",
    "    train_data,train_labels_bin,val_data,val_labels_bin = ldfile.load_data2D_bin(input_directory) \n",
    "    train_set_conv,valid_set_conv = ldfile.load_tf(train_data,train_labels_bin,val_data,val_labels_bin)\n",
    "    t2 = time()\n",
    "    print('Loading data in {} seconds.'.format(round(t2-t1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data,train_labels_bin,val_data,val_labels_bin\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LjGvpnx1ay-P"
   },
   "outputs": [],
   "source": [
    "#### Necessary Imports for Neural Net \n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n",
    "     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6_kNNzvp5-_"
   },
   "outputs": [],
   "source": [
    "def res_identity(x, filters): \n",
    "    ''' renet block where dimension doesnot change.\n",
    "    The skip connection is just simple identity conncection\n",
    "    we will have 3 blocks and then input will be added\n",
    "    '''\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation(activations.relu)(x)\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oMQ2Qg8oA_G"
   },
   "outputs": [],
   "source": [
    "def res_conv(x, s, filters):\n",
    "    '''\n",
    "    here the input size changes, when it goes via conv blocks\n",
    "    so the skip connection uses a projection (conv layer) matrix\n",
    "    ''' \n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKngMdcEJEdI"
   },
   "outputs": [],
   "source": [
    "### Combine the above functions to build 50 layers resnet. \n",
    "def resnet50():\n",
    "    \n",
    "    #input_im = Input(shape=(train_d.shape[1], train_d.shape[2], train_d.shape[3])) # cifar 10 images size\n",
    "    input_im = Input(shape=(train_d[1], train_d[2], train_d[3])) # train_d\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    #x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
    "    x = Dense(9, activation='softmax', kernel_initializer='he_normal', name ='visualized_layer')(x) #multi-class\n",
    "    # define the model \n",
    "\n",
    "    with tf.device(\"/GPU:2\"):\n",
    "        model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzP_9hapzMPx"
   },
   "outputs": [],
   "source": [
    "### Define some Callbacks\n",
    "def lrdecay(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    #print('Learning rate: ', lr)\n",
    "    return lr\n",
    "  # if epoch < 40:\n",
    "  #   return 0.01\n",
    "  # else:\n",
    "  #   return 0.01 * np.math.exp(0.03 * (40 - epoch))\n",
    "lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n",
    "\n",
    "\n",
    "def earlystop(mode):\n",
    "    if mode=='acc':\n",
    "        estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n",
    "    elif mode=='loss':\n",
    "        estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n",
    "    return estop    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQmIe7aXyjiA"
   },
   "outputs": [],
   "source": [
    "resnet50_model = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1592016369227,
     "user": {
      "displayName": "Swap vi",
      "photoUrl": "",
      "userId": "01936573407644251994"
     },
     "user_tz": -540
    },
    "id": "HpJ5jY391JFA",
    "outputId": "af409e75-831e-443b-e921-acf8d35a9727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 12, 2500, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 18, 2506, 1)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 6, 1250, 64)  3200        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 6, 1250, 64)  256         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 6, 1250, 64)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 2, 624, 64)   0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 2, 624, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 2, 624, 64)   256         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 2, 624, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 2, 624, 64)   36928       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 2, 624, 64)   256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 2, 624, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 2, 624, 256)  16640       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 2, 624, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 2, 624, 256)  1024        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 2, 624, 256)  1024        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 2, 624, 256)  0           batch_normalization_109[0][0]    \n",
      "                                                                 batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 2, 624, 256)  0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 2, 624, 64)   16448       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 2, 624, 64)   256         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 2, 624, 64)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 2, 624, 64)   36928       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 2, 624, 64)   256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 2, 624, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 2, 624, 256)  16640       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 2, 624, 256)  1024        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 2, 624, 256)  0           batch_normalization_113[0][0]    \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 2, 624, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 2, 624, 64)   16448       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 2, 624, 64)   256         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 2, 624, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 2, 624, 64)   36928       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 2, 624, 64)   256         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 2, 624, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 2, 624, 256)  16640       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 2, 624, 256)  1024        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2, 624, 256)  0           batch_normalization_116[0][0]    \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 2, 624, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 1, 312, 128)  32896       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 1, 312, 128)  512         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 1, 312, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 1, 312, 128)  147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 1, 312, 128)  512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 1, 312, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 1, 312, 512)  66048       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 1, 312, 512)  131584      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 1, 312, 512)  2048        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 1, 312, 512)  2048        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 1, 312, 512)  0           batch_normalization_119[0][0]    \n",
      "                                                                 batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 1, 312, 512)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 1, 312, 128)  65664       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 1, 312, 128)  512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 1, 312, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 1, 312, 128)  147584      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 1, 312, 128)  512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 1, 312, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 1, 312, 512)  66048       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 1, 312, 512)  2048        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 1, 312, 512)  0           batch_normalization_123[0][0]    \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 1, 312, 512)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 1, 312, 128)  65664       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 1, 312, 128)  512         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 1, 312, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 1, 312, 128)  147584      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 1, 312, 128)  512         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 1, 312, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 1, 312, 512)  66048       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 1, 312, 512)  2048        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 1, 312, 512)  0           batch_normalization_126[0][0]    \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 1, 312, 512)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 1, 312, 128)  65664       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 1, 312, 128)  512         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 1, 312, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 1, 312, 128)  147584      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 1, 312, 128)  512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 1, 312, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 1, 312, 512)  66048       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 1, 312, 512)  2048        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 1, 312, 512)  0           batch_normalization_129[0][0]    \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 1, 312, 512)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 1, 156, 256)  131328      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 1, 156, 256)  1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 1, 156, 256)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 1, 156, 256)  590080      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 1, 156, 256)  1024        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 1, 156, 256)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 1, 156, 1024) 263168      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 1, 156, 1024) 525312      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 1, 156, 1024) 4096        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 1, 156, 1024) 4096        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 1, 156, 1024) 0           batch_normalization_132[0][0]    \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 1, 156, 1024) 0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 1, 156, 256)  262400      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 1, 156, 256)  1024        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 1, 156, 256)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 1, 156, 256)  590080      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 1, 156, 256)  1024        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 1, 156, 256)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 1, 156, 1024) 263168      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 1, 156, 1024) 4096        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 1, 156, 1024) 0           batch_normalization_136[0][0]    \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 1, 156, 1024) 0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 1, 156, 256)  262400      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 1, 156, 256)  1024        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 1, 156, 256)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 1, 156, 256)  590080      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 1, 156, 256)  1024        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 1, 156, 256)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 1, 156, 1024) 263168      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 1, 156, 1024) 4096        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 1, 156, 1024) 0           batch_normalization_139[0][0]    \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 1, 156, 1024) 0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 1, 156, 256)  262400      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 1, 156, 256)  1024        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 1, 156, 256)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 1, 156, 256)  590080      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 1, 156, 256)  1024        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 1, 156, 256)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 1, 156, 1024) 263168      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 1, 156, 1024) 4096        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 1, 156, 1024) 0           batch_normalization_142[0][0]    \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 1, 156, 1024) 0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 1, 156, 256)  262400      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 1, 156, 256)  1024        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 1, 156, 256)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 1, 156, 256)  590080      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 1, 156, 256)  1024        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 1, 156, 256)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 1, 156, 1024) 263168      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 1, 156, 1024) 4096        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 1, 156, 1024) 0           batch_normalization_145[0][0]    \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 1, 156, 1024) 0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 1, 156, 256)  262400      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 1, 156, 256)  1024        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 1, 156, 256)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 1, 156, 256)  590080      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 1, 156, 256)  1024        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 1, 156, 256)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 1, 156, 1024) 263168      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 1, 156, 1024) 4096        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 1, 156, 1024) 0           batch_normalization_148[0][0]    \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 1, 156, 1024) 0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 1, 78, 512)   524800      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 1, 78, 512)   2048        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 1, 78, 512)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 1, 78, 512)   2359808     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 1, 78, 512)   2048        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 1, 78, 512)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 1, 78, 2048)  1050624     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 1, 78, 2048)  2099200     activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 1, 78, 2048)  8192        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 1, 78, 2048)  8192        conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 1, 78, 2048)  0           batch_normalization_151[0][0]    \n",
      "                                                                 batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 1, 78, 2048)  0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 1, 78, 512)   1049088     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 1, 78, 512)   2048        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 1, 78, 512)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 1, 78, 512)   2359808     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 1, 78, 512)   2048        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 1, 78, 512)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 1, 78, 2048)  1050624     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 1, 78, 2048)  8192        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 1, 78, 2048)  0           batch_normalization_155[0][0]    \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 1, 78, 2048)  0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 1, 78, 512)   1049088     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 1, 78, 512)   2048        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 1, 78, 512)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 1, 78, 512)   2359808     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 1, 78, 512)   2048        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 1, 78, 512)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 1, 78, 2048)  1050624     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 1, 78, 2048)  8192        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 1, 78, 2048)  0           batch_normalization_158[0][0]    \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 1, 78, 2048)  0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 39, 2048)  0           activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 79872)        0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "visualized_layer (Dense)        (None, 9)            718857      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,300,297\n",
      "Trainable params: 24,247,177\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJYeyPZQ38JW"
   },
   "outputs": [],
   "source": [
    "resnet50_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), \n",
    "                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5383717,
     "status": "ok",
     "timestamp": 1592021760496,
     "user": {
      "displayName": "Swap vi",
      "photoUrl": "",
      "userId": "01936573407644251994"
     },
     "user_tz": -540
    },
    "id": "TmutGQJp54wv",
    "outputId": "82f13e69-1776-42f7-ba57-12a8f383e9ec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/26 [==============================] - 6s 210ms/step - loss: 432.4942 - acc: 0.2002 - val_loss: 347.6226 - val_acc: 0.1992\n",
      "Epoch 2/5\n",
      "27/26 [==============================] - 6s 209ms/step - loss: 619.1556 - acc: 0.1574 - val_loss: 396.8588 - val_acc: 0.1875\n",
      "Epoch 3/5\n",
      "27/26 [==============================] - 6s 209ms/step - loss: 785.7731 - acc: 0.1348 - val_loss: 412.6528 - val_acc: 0.1602\n",
      "Epoch 4/5\n",
      "27/26 [==============================] - 6s 210ms/step - loss: 668.4009 - acc: 0.1719 - val_loss: 771.7839 - val_acc: 0.0742\n",
      "Epoch 5/5\n",
      "27/26 [==============================] - 6s 211ms/step - loss: 584.5294 - acc: 0.1591 - val_loss: 468.6450 - val_acc: 0.1328\n"
     ]
    }
   ],
   "source": [
    "batch_size=1000 # test with 64, 128, 256\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    resnet_train = resnet50_model.fit(train_set_conv, \n",
    "                                  epochs=5, \n",
    "                                  #verbose = 2,\n",
    "                                  #steps_per_epoch=train_im.shape[0]/batch_size,\n",
    "                                  #steps_per_epoch=train_d.shape[0]/batch_size,\n",
    "                                  steps_per_epoch=train_d[0]/batch_size, #for train_d\n",
    "                                  #validation_steps=valid_im.shape[0]/batch_size, \n",
    "                                  #validation_steps=val_d.shape[0]/batch_size, \n",
    "                                  validation_steps=val_d[0]/batch_size,\n",
    "                                  validation_data=valid_set_conv, \n",
    "                                  callbacks=[lrdecay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2524,
     "status": "ok",
     "timestamp": 1592022962471,
     "user": {
      "displayName": "Swap vi",
      "photoUrl": "",
      "userId": "01936573407644251994"
     },
     "user_tz": -540
    },
    "id": "XbziRYwD8xA_",
    "outputId": "a3e46f1f-3c75-46e8-910a-f7c0b3fb584f"
   },
   "outputs": [],
   "source": [
    "### Plot train and validation curves\n",
    "loss = resnet_train.history['loss']\n",
    "v_loss = resnet_train.history['val_loss']\n",
    "\n",
    "acc = resnet_train.history['acc']\n",
    "v_acc = resnet_train.history['val_acc']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.yscale('log')\n",
    "plt.plot(epochs, loss, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train Loss')\n",
    "plt.plot(epochs, v_loss, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid Loss')\n",
    "plt.ylim(0.01, 10000)\n",
    "plt.xlabel('Epochs', fontsize=11)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, acc, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train Acc')\n",
    "plt.plot(epochs, v_acc, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid Acc') \n",
    "plt.xlabel('Epochs', fontsize=11)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('train_acc.png', dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1427,
     "status": "ok",
     "timestamp": 1592023089900,
     "user": {
      "displayName": "Swap vi",
      "photoUrl": "",
      "userId": "01936573407644251994"
     },
     "user_tz": -540
    },
    "id": "Af5_vzFnEI28",
    "outputId": "f7592cdb-e3f0-4d87-8564-00747fd74d24"
   },
   "outputs": [],
   "source": [
    "#### Plot the Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def conf_matrix(predictions): \n",
    "    ''' Plots conf. matrix and classification report '''\n",
    "    cm=confusion_matrix(test_lab, np.argmax(np.round(predictions), axis=1))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    cr=classification_report(test_lab,\n",
    "                                np.argmax(np.round(predictions), axis=1), \n",
    "                                target_names=[class_types[i] for i in range(len(class_types))])\n",
    "    print(cr)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns_hmp = sns.heatmap(cm, annot=True, xticklabels = [class_types[i] for i in range(len(class_types))], \n",
    "                yticklabels = [class_types[i] for i in range(len(class_types))], fmt=\"d\")\n",
    "    fig = sns_hmp.get_figure()\n",
    "    fig.savefig('heatmap.png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6935,
     "status": "ok",
     "timestamp": 1592023099692,
     "user": {
      "displayName": "Swap vi",
      "photoUrl": "",
      "userId": "01936573407644251994"
     },
     "user_tz": -540
    },
    "id": "xj81pYK-zc9C",
    "outputId": "6886e381-3a7e-4cb2-9f30-b2cb1fb96d49"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1921baec321f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_class_resnet50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_class_resnet50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_im' is not defined"
     ]
    }
   ],
   "source": [
    "pred_class_resnet50 = resnet50_model.predict(val_im)\n",
    "\n",
    "conf_matrix(pred_class_resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6098,
     "status": "ok",
     "timestamp": 1592023127647,
     "user": {
      "displayName": "Swap vi",
      "photoUrl": "",
      "userId": "01936573407644251994"
     },
     "user_tz": -540
    },
    "id": "wws0OyUW0O8F",
    "outputId": "0ed4d0b2-4a3d-4074-dcdf-e69a5dbb083c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 loss:  1.1827166080474854\n",
      "ResNet50 accuracy:  0.6662999987602234\n"
     ]
    }
   ],
   "source": [
    "### Resutls on Test Data; \n",
    "## Check the performance on the test data \n",
    "test_result = resnet50_model.evaluate(test_im, test_lab_categorical, verbose=0)\n",
    "\n",
    "print (\"ResNet50 loss: \", test_result[0])\n",
    "print (\"ResNet50 accuracy: \", test_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_im[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Includes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those are separate normalised input features for the neural network\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"WALKING\", \n",
    "    \"WALKING_UPSTAIRS\", \n",
    "    \"WALKING_DOWNSTAIRS\", \n",
    "    \"SITTING\", \n",
    "    \"STANDING\", \n",
    "    \"LAYING\"\n",
    "] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siddiqmk/LSTM-Human-Activity-Recognition\n",
      "data  LICENSE  LSTM_files  LSTM.ipynb  README.md  RNN.ipynb\n",
      "/home/siddiqmk/Tutorials\n",
      " Basic-LRP   LRP-Time-Series  'UCI HAR Dataset'\n",
      " LICENSE     README.md\t       Visual-Explanation-of-Atari\n",
      "python: can't open file 'download_dataset.py': [Errno 2] No such file or directory\n",
      "/home/siddiqmk/Tutorials\n",
      " Basic-LRP   LRP-Time-Series  'UCI HAR Dataset'\n",
      " LICENSE     README.md\t       Visual-Explanation-of-Atari\n",
      "/home/siddiqmk\n",
      "Cardio\t      HAR\t\t\t       PhysioNet2020\t  test1.ipynb\n",
      "cardio\t      HEY_HAR\t\t\t       physionet.org\t  Tutorials\n",
      "ECG_analysis  LSTM-Human-Activity-Recognition  Physionet_Project\n",
      "\n",
      "Dataset is now located at: /home/siddiqmk/Tutorials/UCI HAR Dataset/\n"
     ]
    }
   ],
   "source": [
    "# Note: Linux bash commands start with a \"!\" inside those \"ipython notebook\" cells\n",
    "\n",
    "DATA_PATH = '/home/siddiqmk/Tutorials/'\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(DATA_PATH)\n",
    "!pwd && ls\n",
    "\n",
    "!python download_dataset.py\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(\"..\")\n",
    "!pwd && ls\n",
    "\n",
    "DATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\n",
    "print(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"train/\"\n",
    "TEST = \"test/\"\n",
    "\n",
    "# Load \"X\" (the neural network's training and testing inputs)\n",
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "    \n",
    "    # Reading through the signal file to cycle through all the train or test file.\n",
    "    for signal_type_path in X_signals_paths:\n",
    "        file = open(signal_type_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        X_signals.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "    \n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "X_train_signals_paths = [\n",
    "    DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "X_test_signals_paths = [\n",
    "    DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "\n",
    "#initiating load function for train and test \n",
    "X_train = load_X(X_train_signals_paths) \n",
    "X_test = load_X(X_test_signals_paths)\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]], \n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    \n",
    "    # Substract 1 to each output class for friendly 0-based indexing \n",
    "    return y_ - 1\n",
    "\n",
    "y_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\n",
    "y_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(2947, 128, 9) (2947, 1) 0.09913992 0.39567086\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n",
      "[[[ 1.165315e-02 -2.939904e-02  1.068262e-01 ...  1.041216e+00\n",
      "   -2.697959e-01  2.377977e-02]\n",
      "  [ 1.310909e-02 -3.972867e-02  1.524549e-01 ...  1.041803e+00\n",
      "   -2.800250e-01  7.629271e-02]\n",
      "  [ 1.126885e-02 -5.240586e-02  2.168462e-01 ...  1.039086e+00\n",
      "   -2.926631e-01  1.474754e-01]\n",
      "  ...\n",
      "  [ 1.291511e-03  1.173502e-02  3.665587e-03 ...  9.930164e-01\n",
      "   -2.599865e-01  1.443951e-01]\n",
      "  [ 1.469997e-03  9.517414e-03  4.041945e-03 ...  9.932414e-01\n",
      "   -2.620643e-01  1.447033e-01]\n",
      "  [ 2.573841e-03  7.305069e-03  4.888436e-03 ...  9.943906e-01\n",
      "   -2.641348e-01  1.454939e-01]]\n",
      "\n",
      " [[ 9.279629e-03  6.650520e-03 -2.631933e-02 ...  9.991921e-01\n",
      "   -2.649349e-01  1.256164e-01]\n",
      "  [ 4.929711e-03  1.864973e-02 -2.688753e-02 ...  9.946787e-01\n",
      "   -2.532142e-01  1.256249e-01]\n",
      "  [ 3.953596e-03  1.553950e-02 -3.663861e-02 ...  9.935518e-01\n",
      "   -2.565887e-01  1.163814e-01]\n",
      "  ...\n",
      "  [ 7.787600e-03  4.730625e-03  1.412899e-02 ...  1.001861e+00\n",
      "   -2.619359e-01  1.527878e-01]\n",
      "  [ 3.433489e-03 -4.619849e-03  1.338054e-03 ...  9.975208e-01\n",
      "   -2.713225e-01  1.398428e-01]\n",
      "  [-1.238678e-03 -1.322889e-02 -1.703861e-02 ...  9.928615e-01\n",
      "   -2.799715e-01  1.213135e-01]]\n",
      "\n",
      " [[ 5.731945e-03  7.304842e-03  1.021286e-02 ...  9.975931e-01\n",
      "   -2.639912e-01  1.507741e-01]\n",
      "  [ 7.065650e-03  7.330912e-03  1.341419e-02 ...  9.989703e-01\n",
      "   -2.638194e-01  1.539427e-01]\n",
      "  [ 5.109758e-03  7.153458e-03  3.646559e-03 ...  9.970574e-01\n",
      "   -2.638495e-01  1.441536e-01]\n",
      "  ...\n",
      "  [-7.428461e-04 -9.629137e-03 -2.500924e-03 ...  9.918802e-01\n",
      "   -2.836712e-01  1.326780e-01]\n",
      "  [-1.923356e-03 -6.425974e-03 -2.524952e-03 ...  9.906626e-01\n",
      "   -2.805970e-01  1.326941e-01]\n",
      "  [-4.304617e-03 -7.932046e-03 -3.140111e-03 ...  9.882446e-01\n",
      "   -2.822329e-01  1.321175e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.476465e-01  5.519791e-03  1.025031e-02 ...  8.213505e-01\n",
      "   -2.484623e-01 -2.216934e-01]\n",
      "  [-1.699026e-01  3.235187e-02  2.632373e-02 ...  7.991996e-01\n",
      "   -2.232599e-01 -2.045561e-01]\n",
      "  [-1.686980e-01  7.826144e-02 -2.703439e-02 ...  8.004623e-01\n",
      "   -1.790170e-01 -2.568719e-01]\n",
      "  ...\n",
      "  [ 4.978930e-01 -3.158365e-01 -2.321939e-02 ...  1.463170e+00\n",
      "   -5.515283e-01 -2.723974e-01]\n",
      "  [ 2.141275e-01 -3.121422e-01  1.814949e-01 ...  1.179223e+00\n",
      "   -5.472997e-01 -6.773376e-02]\n",
      "  [-1.145089e-01 -2.553472e-01  3.870347e-01 ...  8.504963e-01\n",
      "   -4.900368e-01  1.378256e-01]]\n",
      "\n",
      " [[ 7.122683e-02 -1.498122e-01 -1.659306e-01 ...  1.037668e+00\n",
      "   -3.971532e-01 -3.940817e-01]\n",
      "  [-8.866530e-02 -3.755543e-02 -8.708159e-02 ...  8.780725e-01\n",
      "   -2.848634e-01 -3.151097e-01]\n",
      "  [-7.067473e-02 -1.615178e-02  1.401189e-02 ...  8.963897e-01\n",
      "   -2.635297e-01 -2.139040e-01]\n",
      "  ...\n",
      "  [ 1.859878e-01  7.344366e-03  2.383924e-01 ...  1.156389e+00\n",
      "   -2.283478e-01 -3.512052e-03]\n",
      "  [ 2.737114e-01 -2.279012e-02  1.302276e-01 ...  1.243857e+00\n",
      "   -2.583220e-01 -1.117857e-01]\n",
      "  [ 3.536738e-01 -1.118625e-01 -3.402252e-02 ...  1.323546e+00\n",
      "   -3.472416e-01 -2.760682e-01]]\n",
      "\n",
      " [[-1.936425e-01 -1.907511e-01  1.958357e-01 ...  7.713622e-01\n",
      "   -4.250499e-01 -5.327655e-02]\n",
      "  [-6.498738e-02 -2.035990e-01 -1.531400e-01 ...  9.000949e-01\n",
      "   -4.375916e-01 -4.020727e-01]\n",
      "  [-9.712210e-02 -2.083832e-01 -2.710627e-01 ...  8.681034e-01\n",
      "   -4.421595e-01 -5.197379e-01]\n",
      "  ...\n",
      "  [-5.075521e-02 -1.047171e-01  1.732707e-01 ...  9.188616e-01\n",
      "   -3.516799e-01 -7.253919e-02]\n",
      "  [-1.980675e-02 -2.076396e-02  1.956384e-01 ...  9.494752e-01\n",
      "   -2.675260e-01 -5.097549e-02]\n",
      "  [-1.104015e-02  5.243883e-02  2.184321e-01 ...  9.578348e-01\n",
      "   -1.941603e-01 -2.892477e-02]]]\n"
     ]
    }
   ],
   "source": [
    "# Input Data \n",
    "\n",
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # 2947 testing series\n",
    "n_steps = len(X_train[0])  # 128 timesteps per series\n",
    "n_input = len(X_train[0][0])  # 9 input parameters per timestep,\n",
    "\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 1500\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_RNN(_X, _weights, _biases):\n",
    "    # Function returns a tensorflow LSTM (RNN) artificial neural network from given parameters. \n",
    "    # Moreover, two LSTM cells are stacked which adds deepness to the neural network. \n",
    "\n",
    "    # (NOTE: This step could be greatly optimised by shaping the dataset once\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) \n",
    "    # new shape: (n_steps*batch_size, n_input)\n",
    "    \n",
    "    # ReLU activation, thanks to Yu Zhao for adding this improvement here:\n",
    "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(_X, n_steps, 0) \n",
    "    # new shape: n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    # Get LSTM cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "\n",
    "    # Get last time step's output feature for a \"many-to-one\" style classifier, \n",
    "    # as in the image describing RNNs at the top of this page\n",
    "    lstm_last_output = outputs[-1]\n",
    "    \n",
    "    # Linear activation\n",
    "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n",
    "\n",
    "\n",
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index] \n",
    "\n",
    "    return batch_s\n",
    "\n",
    "\n",
    "def one_hot(y_, n_classes=n_classes):\n",
    "    # Function to encode neural one-hot output labels from number indexes \n",
    "    # e.g.: \n",
    "    # one_hot(y_=[[5], [0], [3]], n_classes=6):\n",
    "    #     return [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    return np.eye(n_classes)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
